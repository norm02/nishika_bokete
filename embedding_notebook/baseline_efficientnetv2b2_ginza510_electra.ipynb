{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exPnU6gJ9_8L"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9onj0RDDiWU4"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sudachitra\n",
        "! wget https://sudachi.s3.ap-northeast-1.amazonaws.com/chitra/chiTra-1.0.tar.gz\n",
        "! tar -zxvf chiTra-1.0.tar.gz"
      ],
      "metadata": {
        "id": "vp4pKg-_qzx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U ginza ja_ginza_electra\n",
        "!git lfs install\n",
        "!pip install -U \"spacy[cuda110]\""
      ],
      "metadata": {
        "id": "n8zVvFNYjpZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U ginza https://github.com/megagonlabs/ginza/releases/download/latest/ja_ginza_electra-latest-with-model.tar.gz"
      ],
      "metadata": {
        "id": "k0NSP4xrluuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-efficientnet-v2"
      ],
      "metadata": {
        "id": "vWYbo1yXrz-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23tLb36S_nX-"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet transformers==4.18.0\n",
        "!pip install --quiet tokenizers==0.12.1\n",
        "!pip install --quiet sentencepiece\n",
        "!pip install --quiet japanize-matplotlib\n",
        "!pip install transformers fugashi ipadic >> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Myu_A_Kc_zyK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import japanize_matplotlib\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "\n",
        "from time import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "from contextlib import contextmanager\n",
        "import lightgbm as lgb\n",
        "\n",
        "import re\n",
        "import requests\n",
        "import unicodedata\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from bs4 import BeautifulSoup\n",
        "nltk.download(['wordnet', 'stopwords', 'punkt'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKk0ahsSIzJY"
      },
      "outputs": [],
      "source": [
        "pd.set_option('max_rows', 400)\n",
        "pd.set_option('max_columns', 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9WsZjx-NT-O"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed=1234):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "seed_everything(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajiBxfC2ABC4"
      },
      "outputs": [],
      "source": [
        "INPUT = \"/content/drive/MyDrive/nishika/\" # 所望のディレクトリに変更してください。\n",
        "train_image_path = \"/content/drive/MyDrive/nishika/train/\"\n",
        "test_image_path = \"/content/drive/MyDrive/nishika/test/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh06H3rFAPA5"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(os.path.join(INPUT, \"train.csv\"))\n",
        "test_df = pd.read_csv(os.path.join(INPUT, \"test.csv\"))\n",
        "submission_df = pd.read_csv(os.path.join(INPUT, \"sample_submission.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sofMAgYkAqmU"
      },
      "outputs": [],
      "source": [
        "print(f\"train_data: {train_df.shape}\")\n",
        "display(train_df.head())\n",
        "\n",
        "print(f\"test_data: {test_df.shape}\")\n",
        "display(test_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2u7Txq3BgnO"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from keras.models import Model\n",
        "from keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\n",
        "import keras.backend as K\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from keras.applications.efficientnet_v2 import preprocess_input, EfficientNetV2B2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffiWtaKaHCe9"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    img_size = 260\n",
        "    batch_size = 17"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2VMGIT1HFaE"
      },
      "outputs": [],
      "source": [
        "def resize_to_square(im):\n",
        "    old_size = im.shape[:2] \n",
        "    ratio = float(CFG.img_size)/max(old_size)\n",
        "    new_size = tuple([int(x*ratio) for x in old_size])\n",
        "    # 画像サイズを224×224に変更します\n",
        "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
        "    delta_w = CFG.img_size - new_size[1]\n",
        "    delta_h = CFG.img_size - new_size[0]\n",
        "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
        "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
        "    color = [0, 0, 0]\n",
        "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
        "    return new_im\n",
        "\n",
        "\n",
        "def load_image(ids, is_train=True):\n",
        "  if is_train:\n",
        "    image = cv2.imread(train_image_path+ids)\n",
        "  else:\n",
        "    image = cv2.imread(test_image_path+ids)\n",
        "  new_image = resize_to_square(image)\n",
        "  new_image = preprocess_input(new_image)\n",
        "  return new_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fuel9pkhenp"
      },
      "outputs": [],
      "source": [
        "\n",
        "inp = Input((260,260,3))\n",
        "backbone = EfficientNetV2B2(input_tensor = inp, include_top = False)\n",
        "x = backbone.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Lambda(lambda x: K.expand_dims(x,axis = -1))(x)\n",
        "x = AveragePooling1D(4)(x)\n",
        "out = Lambda(lambda x: x[:,:,0])(x)\n",
        "\n",
        "m = Model(inp,out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E__Maa9sHotq"
      },
      "outputs": [],
      "source": [
        "\n",
        "image_df_train = train_df[[\"id\", \"odai_photo_file_name\"]].copy()\n",
        "image_df_train.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88WZT_GRIZJd"
      },
      "outputs": [],
      "source": [
        "image_ids = image_df_train[\"odai_photo_file_name\"].values\n",
        "n_batches = len(image_ids) // CFG.batch_size + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6XwArKgIcCr"
      },
      "outputs": [],
      "source": [
        "\n",
        "features = {}\n",
        "for b in tqdm(range(n_batches)):\n",
        "    start = b*CFG.batch_size\n",
        "    end = (b+1)*CFG.batch_size\n",
        "    batch_ids = image_ids[start:end]\n",
        "    batch_images = np.zeros((len(batch_ids),CFG.img_size,CFG.img_size,3))\n",
        "    for i,image_id in enumerate(batch_ids):\n",
        "        try:\n",
        "            batch_images[i] = load_image(image_id)\n",
        "        except:\n",
        "          print(\"Error\")\n",
        "    batch_preds = m.predict(batch_images)\n",
        "    for i,image_id in enumerate(batch_ids):\n",
        "        features[image_id] = batch_preds[i]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3x9JsVsI3ht"
      },
      "outputs": [],
      "source": [
        "image_feature = pd.DataFrame.from_dict(features, orient='index').add_prefix(\"EfficientNetV2B2_\").reset_index()\n",
        "image_feature.rename(columns={\"index\":\"odai_photo_file_name\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNZpZ19iJEun"
      },
      "outputs": [],
      "source": [
        "# trainのデータに結合します。\n",
        "train_df = pd.merge(train_df, image_feature, on=\"odai_photo_file_name\", how=\"left\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLa8BVy5y4mh"
      },
      "outputs": [],
      "source": [
        "train_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARlBMAiBxcVP"
      },
      "outputs": [],
      "source": [
        "\n",
        "# testデータでも同様なことを行って行きます\n",
        "image_df_test = test_df[[\"id\", \"odai_photo_file_name\"]].copy()\n",
        "\n",
        "image_ids = image_df_test[\"odai_photo_file_name\"].values\n",
        "n_batches = len(image_ids) // CFG.batch_size + 1\n",
        "\n",
        "\n",
        "features = {}\n",
        "for b in tqdm(range(n_batches)):\n",
        "    start = b*CFG.batch_size\n",
        "    end = (b+1)*CFG.batch_size\n",
        "    batch_ids = image_ids[start:end]\n",
        "    batch_images = np.zeros((len(batch_ids),CFG.img_size,CFG.img_size,3))\n",
        "    for i,image_id in enumerate(batch_ids):\n",
        "        try:\n",
        "            batch_images[i] = load_image(image_id, is_train=False)\n",
        "        except:\n",
        "          print(\"Error\")\n",
        "    batch_preds = m.predict(batch_images)\n",
        "    for i,image_id in enumerate(batch_ids):\n",
        "        features[image_id] = batch_preds[i]\n",
        "\n",
        "image_feature = pd.DataFrame.from_dict(features, orient='index').add_prefix(\"EfficientNetV2B2_\").reset_index()\n",
        "image_feature.rename(columns={\"index\":\"odai_photo_file_name\"}, inplace=True)\n",
        "\n",
        "test_df = pd.merge(test_df, image_feature, on=\"odai_photo_file_name\", how=\"left\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xtltEAbzoko"
      },
      "outputs": [],
      "source": [
        "test_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv('embedding_train_image_EfficientNetV2B2')"
      ],
      "metadata": {
        "id": "X7nKCQ-qnhbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('embedding_test_image_EfficientNetV2B2')"
      ],
      "metadata": {
        "id": "dGrOhTaKnmZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6-Kj_NkNuBB"
      },
      "outputs": [],
      "source": [
        "from transformers import ElectraModel\n",
        "from sudachitra import ElectraSudachipyTokenizer\n",
        "\n",
        "class ElectraSequenceVectorizer:\n",
        "    def __init__(self, model_name: str):\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.model_name = model_name\n",
        "        self.tokenizer = ElectraSudachipyTokenizer.from_pretrained(self.model_name)\n",
        "        #self.tokenizer.do_lower_case = True \n",
        "        self.electra_model = ElectraModel.from_pretrained(self.model_name)\n",
        "        self.electra_model = self.electra_model.to(self.device)\n",
        "        self.max_len = 256\n",
        "\n",
        "\n",
        "    def vectorize(self, sentence : str) -> np.array:\n",
        "        inp = self.tokenizer.encode(sentence)\n",
        "        len_inp = len(inp)\n",
        "\n",
        "        if len_inp >= self.max_len:\n",
        "            inputs = inp[:self.max_len]\n",
        "            masks = [1] * self.max_len\n",
        "        else:\n",
        "            inputs = inp + [0] * (self.max_len - len_inp)\n",
        "            masks = [1] * len_inp + [0] * (self.max_len - len_inp)\n",
        "\n",
        "        inputs_tensor = torch.tensor([inputs], dtype=torch.long).to(self.device)\n",
        "        masks_tensor = torch.tensor([masks], dtype=torch.long).to(self.device)\n",
        "\n",
        "        electra_out = self.electra_model(inputs_tensor, masks_tensor)\n",
        "        seq_out = electra_out['last_hidden_state']\n",
        "\n",
        "        if torch.cuda.is_available():    \n",
        "            return seq_out[0][0].cpu().detach().numpy()\n",
        "        else:\n",
        "            return seq_out[0][0].detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZ0fYQtXN0Mn"
      },
      "outputs": [],
      "source": [
        "ESV = ElectraSequenceVectorizer('megagonlabs/transformers-ud-japanese-electra-base-ginza-510')\n",
        "\n",
        "## テキストの欠損値を補間します\n",
        "train_df[\"text\"] = train_df[\"text\"].fillna('NaN')\n",
        "test_df[\"text\"] = test_df[\"text\"].fillna('NaN')\n",
        "\n",
        "## BERT特徴量 \n",
        "features_text_train = np.stack(train_df[\"text\"].fillna(\"\").map(lambda x: ESV.vectorize(x).reshape(-1)).values)\n",
        "features_text_test = np.stack(test_df[\"text\"].fillna(\"\").map(lambda x: ESV.vectorize(x).reshape(-1)).values)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## テキスト特徴量\n",
        "features_text_train_df = pd.DataFrame(features_text_train).add_prefix(\"ginza510-electra-large-text\")\n",
        "features_text_test_df = pd.DataFrame(features_text_test).add_prefix(\"ginza510-electra-large-text\")\n",
        "\n",
        "train_df = pd.concat([train_df, features_text_train_df], axis=1)\n",
        "test_df = pd.concat([test_df, features_text_test_df], axis=1)"
      ],
      "metadata": {
        "id": "-J4qAzFmG_s3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqlFKSDJ_MuL"
      },
      "outputs": [],
      "source": [
        "train_df.to_csv('embedding_train_text_ginza510_electra')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcsVcItHAIPQ"
      },
      "outputs": [],
      "source": [
        "test_df.to_csv('embedding_test_text_ginza510_electra')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
