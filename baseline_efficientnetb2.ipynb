{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U git+https://github.com/qubvel/efficientnet"
      ],
      "metadata": {
        "id": "f-5_hv2UwfEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exPnU6gJ9_8L"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "9onj0RDDiWU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet transformers==4.18.0\n",
        "!pip install --quiet tokenizers==0.12.1\n",
        "!pip install --quiet sentencepiece\n",
        "!pip install --quiet japanize-matplotlib\n",
        "!pip install transformers fugashi ipadic >> /dev/null"
      ],
      "metadata": {
        "id": "23tLb36S_nX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import japanize_matplotlib\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "\n",
        "from time import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "from contextlib import contextmanager\n",
        "import lightgbm as lgb\n",
        "\n",
        "import re\n",
        "import requests\n",
        "import unicodedata\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from bs4 import BeautifulSoup\n",
        "nltk.download(['wordnet', 'stopwords', 'punkt'])"
      ],
      "metadata": {
        "id": "Myu_A_Kc_zyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed=1234):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "seed_everything(42)"
      ],
      "metadata": {
        "id": "z9WsZjx-NT-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT = \"/content/drive/MyDrive/nishika/\" # 所望のディレクトリに変更してください。\n",
        "train_image_path = \"/content/drive/MyDrive/nishika/train/\"\n",
        "test_image_path = \"/content/drive/MyDrive/nishika/test/\""
      ],
      "metadata": {
        "id": "ajiBxfC2ABC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(os.path.join(INPUT, \"train.csv\"))\n",
        "test_df = pd.read_csv(os.path.join(INPUT, \"test.csv\"))\n",
        "submission_df = pd.read_csv(os.path.join(INPUT, \"sample_submission.csv\"))"
      ],
      "metadata": {
        "id": "Nh06H3rFAPA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"train_data: {train_df.shape}\")\n",
        "display(train_df.head())\n",
        "\n",
        "print(f\"test_data: {test_df.shape}\")\n",
        "display(test_df.head())"
      ],
      "metadata": {
        "id": "sofMAgYkAqmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from keras.models import Model\n",
        "from keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\n",
        "import keras.backend as K\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from keras.applications.efficientnet import preprocess_input, EfficientNetB2"
      ],
      "metadata": {
        "id": "Y2u7Txq3BgnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    img_size = 260\n",
        "    batch_size = 17"
      ],
      "metadata": {
        "id": "ffiWtaKaHCe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_to_square(im):\n",
        "    old_size = im.shape[:2] \n",
        "    ratio = float(CFG.img_size)/max(old_size)\n",
        "    new_size = tuple([int(x*ratio) for x in old_size])\n",
        "    # 画像サイズを260×260に変更します\n",
        "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
        "    delta_w = CFG.img_size - new_size[1]\n",
        "    delta_h = CFG.img_size - new_size[0]\n",
        "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
        "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
        "    color = [0, 0, 0]\n",
        "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
        "    return new_im\n",
        "\n",
        "\n",
        "def load_image(ids, is_train=True):\n",
        "  if is_train:\n",
        "    image = cv2.imread(train_image_path+ids)\n",
        "  else:\n",
        "    image = cv2.imread(test_image_path+ids)\n",
        "  new_image = resize_to_square(image)\n",
        "  new_image = preprocess_input(new_image)\n",
        "  return new_image"
      ],
      "metadata": {
        "id": "y2VMGIT1HFaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = Input((260,260,3))\n",
        "backbone = EfficientNetB2(input_tensor = inp, include_top = False)\n",
        "x = backbone.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Lambda(lambda x: K.expand_dims(x,axis = -1))(x)\n",
        "x = AveragePooling1D(4)(x)\n",
        "out = Lambda(lambda x: x[:,:,0])(x)\n",
        "\n",
        "m = Model(inp,out)"
      ],
      "metadata": {
        "id": "6fuel9pkhenp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_df_train = train_df[[\"id\", \"odai_photo_file_name\"]].copy()\n",
        "image_df_train.head()"
      ],
      "metadata": {
        "id": "E__Maa9sHotq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_ids = image_df_train[\"odai_photo_file_name\"].values\n",
        "n_batches = len(image_ids) // CFG.batch_size + 1"
      ],
      "metadata": {
        "id": "88WZT_GRIZJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = {}\n",
        "for b in tqdm(range(n_batches)):\n",
        "    start = b*CFG.batch_size\n",
        "    end = (b+1)*CFG.batch_size\n",
        "    batch_ids = image_ids[start:end]\n",
        "    batch_images = np.zeros((len(batch_ids),CFG.img_size,CFG.img_size,3))\n",
        "    for i,image_id in enumerate(batch_ids):\n",
        "        try:\n",
        "            batch_images[i] = load_image(image_id)\n",
        "        except:\n",
        "          print(\"Error\")\n",
        "    batch_preds = m.predict(batch_images)\n",
        "    for i,image_id in enumerate(batch_ids):\n",
        "        features[image_id] = batch_preds[i]"
      ],
      "metadata": {
        "id": "g6XwArKgIcCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_feature = pd.DataFrame.from_dict(features, orient='index').add_prefix(\"EfficientNetB2_\").reset_index()\n",
        "image_feature.rename(columns={\"index\":\"odai_photo_file_name\"}, inplace=True)"
      ],
      "metadata": {
        "id": "T3x9JsVsI3ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainのデータに結合します。\n",
        "train_df = pd.merge(train_df, image_feature, on=\"odai_photo_file_name\", how=\"left\")"
      ],
      "metadata": {
        "id": "pNZpZ19iJEun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "id": "TLa8BVy5y4mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testデータでも同様なことを行って行きます\n",
        "image_df_test = test_df[[\"id\", \"odai_photo_file_name\"]].copy()\n",
        "\n",
        "image_ids = image_df_test[\"odai_photo_file_name\"].values\n",
        "n_batches = len(image_ids) // CFG.batch_size + 1\n",
        "\n",
        "\n",
        "features = {}\n",
        "for b in tqdm(range(n_batches)):\n",
        "    start = b*CFG.batch_size\n",
        "    end = (b+1)*CFG.batch_size\n",
        "    batch_ids = image_ids[start:end]\n",
        "    batch_images = np.zeros((len(batch_ids),CFG.img_size,CFG.img_size,3))\n",
        "    for i,image_id in enumerate(batch_ids):\n",
        "        try:\n",
        "            batch_images[i] = load_image(image_id, is_train=False)\n",
        "        except:\n",
        "          print(\"Error\")\n",
        "    batch_preds = m.predict(batch_images)\n",
        "    for i,image_id in enumerate(batch_ids):\n",
        "        features[image_id] = batch_preds[i]\n",
        "\n",
        "image_feature = pd.DataFrame.from_dict(features, orient='index').add_prefix(\"EfficientnetB2_\").reset_index()\n",
        "image_feature.rename(columns={\"index\":\"odai_photo_file_name\"}, inplace=True)\n",
        "\n",
        "test_df = pd.merge(test_df, image_feature, on=\"odai_photo_file_name\", how=\"left\")"
      ],
      "metadata": {
        "id": "ARlBMAiBxcVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.shape"
      ],
      "metadata": {
        "id": "_xtltEAbzoko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv('embedding_train_image_EfficientNetB2')"
      ],
      "metadata": {
        "id": "vqlFKSDJ_MuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('embedding_test_image_EfficientNetB2')"
      ],
      "metadata": {
        "id": "fcsVcItHAIPQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}