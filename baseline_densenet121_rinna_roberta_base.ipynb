{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/norm02/nishika_bokete/blob/main/baseline_densenet121_rinna_roberta_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ボケ判定AIを作ろう！-チュートリアル1\n",
        "このnotebookは、Nishikaコンペティション [ボケ判定AIを作ろう！](https://www.nishika.com/competitions/) のチュートリアルです。\n",
        "\n",
        "「ボケて」データを用いて、画像データと文章からそのボケてが面白いか面白くないかを予測することをテーマとしています。\n",
        "\n",
        "このNotebookでは、画像とテキストそれぞれの特徴量生成を以下のような方法で行っていきます。\n",
        "\n",
        "- CNNモデルを用いた画像データの特徴量化\n",
        "- BERTモデルを用いたテキストデータの特徴量化\n",
        "\n",
        "特徴量の作成では、テキストと画像それぞれ別々で作成していますので、画像データとテキストデータを組み合わせた特徴量を入れることで精度向上が見込めるかも知れませんので、いろいろと試していただければと思います。"
      ],
      "metadata": {
        "id": "m0ayzrjm-DgE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| 要素 | 説明 |\n",
        "| ---- | ---- |\n",
        "|id | ID|\n",
        "|odai_photo_file_name | ボケてのお題画像|\n",
        "|text | ボケての文章|\n",
        "|is_laugh | 面白さ（面白い：１、面白くない：０）|\n"
      ],
      "metadata": {
        "id": "EjvjywgsCuKU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ディレクトリ構成は以下のように設定します\n",
        "\n",
        "```\n",
        "├── train.zip\n",
        "│ ├── xxx.jpg\n",
        "│ └── yyy.jpg\n",
        "├── test.zip\n",
        "│ ├── xxx.jpg\n",
        "│ └── yyy.jpg\n",
        "├── train.csv\n",
        "├── test.csv\n",
        "├── sample_submission.csv\n",
        "└── submission.csv(今回のbaselineで生成されるsubmissionファイル)\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "### setting\n",
        "ページ上部の「ランタイム」>「ランタイムのタイプを変更」から「GPU」「ハイメモリ」を選択"
      ],
      "metadata": {
        "id": "9YJVABJ8CqoX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exPnU6gJ9_8L",
        "outputId": "d3f59c92-62a5-4651-9219-82b8660f3b00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9onj0RDDiWU4",
        "outputId": "51e4db9c-1614-462a-e88d-89f6e616f9d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Library"
      ],
      "metadata": {
        "id": "JGai1EPR_tEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet transformers==4.18.0\n",
        "!pip install --quiet tokenizers==0.12.1\n",
        "!pip install --quiet sentencepiece\n",
        "!pip install --quiet japanize-matplotlib\n",
        "!pip install transformers fugashi ipadic >> /dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23tLb36S_nX-",
        "outputId": "527a936f-366f-4c3a-87a5-23e9122a4f1a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.0 MB 14.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 44.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 880 kB 68.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 86.7 MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 12.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 15.0 MB/s \n",
            "\u001b[?25h  Building wheel for japanize-matplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import japanize_matplotlib\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertJapaneseTokenizer\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "\n",
        "from time import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "from contextlib import contextmanager\n",
        "import lightgbm as lgb\n",
        "\n",
        "import re\n",
        "import requests\n",
        "import unicodedata\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from bs4 import BeautifulSoup\n",
        "nltk.download(['wordnet', 'stopwords', 'punkt'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myu_A_Kc_zyK",
        "outputId": "a181439d-c7ee-4b58-bf40-8de56939a913"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting"
      ],
      "metadata": {
        "id": "dCYVrA1lAB8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed=1234):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "seed_everything(42)"
      ],
      "metadata": {
        "id": "z9WsZjx-NT-O"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#画像データのzipを解凍します\n",
        "!unzip /content/drive/MyDrive/Nishika/bokete/train.zip -d /content/train\n",
        "!unzip /content/drive/MyDrive/Nishika/bokete/test.zip -d /content/test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj0Rsc8wvhEu",
        "outputId": "9fe62895-7e3f-48eb-8ede-0a607bd71b5d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/drive/MyDrive/Nishika/bokete/train.zip, /content/drive/MyDrive/Nishika/bokete/train.zip.zip or /content/drive/MyDrive/Nishika/bokete/train.zip.ZIP.\n",
            "unzip:  cannot find or open /content/drive/MyDrive/Nishika/bokete/test.zip, /content/drive/MyDrive/Nishika/bokete/test.zip.zip or /content/drive/MyDrive/Nishika/bokete/test.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT = \"/content/drive/MyDrive/nishika\" # 所望のディレクトリに変更してください。\n",
        "train_image_path = \"/content/drive/MyDrive/nishika/train/\"\n",
        "test_image_path = \"/content/drive/MyDrive/nishika/test/\""
      ],
      "metadata": {
        "id": "ajiBxfC2ABC4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read Data\n",
        "学習データと推論データについて、目的変数の分布などを確認していきます。"
      ],
      "metadata": {
        "id": "qbdARhsQASHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(os.path.join(INPUT, \"train.csv\"))\n",
        "test_df = pd.read_csv(os.path.join(INPUT, \"test.csv\"))\n",
        "submission_df = pd.read_csv(os.path.join(INPUT, \"sample_submission.csv\"))"
      ],
      "metadata": {
        "id": "Nh06H3rFAPA5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"train_data: {train_df.shape}\")\n",
        "display(train_df.head())\n",
        "\n",
        "print(f\"test_data: {test_df.shape}\")\n",
        "display(test_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "sofMAgYkAqmU",
        "outputId": "cc6a2b72-753e-4efc-e3e1-edb1cbefac5c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data: (24962, 4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          id odai_photo_file_name  \\\n",
              "0  ge5kssftl       9fkys1gb2r.jpg   \n",
              "1  r7sm6tvkj       c6ag0m1lak.jpg   \n",
              "2  yp5aze0bh       whtn6gb9ww.jpg   \n",
              "3  ujaixzo56       6yk5cwmrsy.jpg   \n",
              "4  7vkeveptl       0i9gsa2jsm.jpg   \n",
              "\n",
              "                                            text  is_laugh  \n",
              "0             君しょっちゅうソレ自慢するけど、ツムジ２個ってそんなに嬉しいのかい？         0  \n",
              "1                            これでバレない？授業中寝てもバレない？         0  \n",
              "2  「あなたも感じる？」\\n『ああ…、感じてる…』\\n「後ろに幽霊いるよね…」\\n『女のな…』         0  \n",
              "3                 大塚愛聞いてたらお腹減った…さく、らんぼと牛タン食べたい…          0  \n",
              "4                                    熊だと思ったら嫁だった         0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5473086-2c11-4050-a400-ec1d87c8ea6a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>odai_photo_file_name</th>\n",
              "      <th>text</th>\n",
              "      <th>is_laugh</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ge5kssftl</td>\n",
              "      <td>9fkys1gb2r.jpg</td>\n",
              "      <td>君しょっちゅうソレ自慢するけど、ツムジ２個ってそんなに嬉しいのかい？</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>r7sm6tvkj</td>\n",
              "      <td>c6ag0m1lak.jpg</td>\n",
              "      <td>これでバレない？授業中寝てもバレない？</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yp5aze0bh</td>\n",
              "      <td>whtn6gb9ww.jpg</td>\n",
              "      <td>「あなたも感じる？」\\n『ああ…、感じてる…』\\n「後ろに幽霊いるよね…」\\n『女のな…』</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ujaixzo56</td>\n",
              "      <td>6yk5cwmrsy.jpg</td>\n",
              "      <td>大塚愛聞いてたらお腹減った…さく、らんぼと牛タン食べたい…</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7vkeveptl</td>\n",
              "      <td>0i9gsa2jsm.jpg</td>\n",
              "      <td>熊だと思ったら嫁だった</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5473086-2c11-4050-a400-ec1d87c8ea6a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d5473086-2c11-4050-a400-ec1d87c8ea6a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d5473086-2c11-4050-a400-ec1d87c8ea6a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_data: (6000, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          id odai_photo_file_name  \\\n",
              "0  rfdjcfsqq       nc1kez326b.jpg   \n",
              "1  tsgqmfpef       49xt2fmjw0.jpg   \n",
              "2  owjcthkz2       9dtscjmyfh.jpg   \n",
              "3  rvgaocjyy       osa3n56tiv.jpg   \n",
              "4  uxtwu5i69       yb1yqs4pvb.jpg   \n",
              "\n",
              "                                                text  \n",
              "0                          僕のママ、キャラ弁のゆでたまごに８時間かかったんだ  \n",
              "1                                          かわいいが作れた！  \n",
              "2                                           来世の志茂田景樹  \n",
              "3                       ちょ、あの、オカン、これ水風呂やねんけど、なんの冗談??  \n",
              "4  「今日は皆さんにザリガニと消防車の違いを知ってもらいたいと思います」『どっちも同じだろ。両方...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61e9d313-c0d2-427d-ab42-7a29c5c276b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>odai_photo_file_name</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rfdjcfsqq</td>\n",
              "      <td>nc1kez326b.jpg</td>\n",
              "      <td>僕のママ、キャラ弁のゆでたまごに８時間かかったんだ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tsgqmfpef</td>\n",
              "      <td>49xt2fmjw0.jpg</td>\n",
              "      <td>かわいいが作れた！</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>owjcthkz2</td>\n",
              "      <td>9dtscjmyfh.jpg</td>\n",
              "      <td>来世の志茂田景樹</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rvgaocjyy</td>\n",
              "      <td>osa3n56tiv.jpg</td>\n",
              "      <td>ちょ、あの、オカン、これ水風呂やねんけど、なんの冗談??</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>uxtwu5i69</td>\n",
              "      <td>yb1yqs4pvb.jpg</td>\n",
              "      <td>「今日は皆さんにザリガニと消防車の違いを知ってもらいたいと思います」『どっちも同じだろ。両方...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61e9d313-c0d2-427d-ab42-7a29c5c276b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61e9d313-c0d2-427d-ab42-7a29c5c276b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61e9d313-c0d2-427d-ab42-7a29c5c276b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Image Features\n",
        "\n",
        "ボケてというものは、画像と文章の組み合わせで面白さを表現しているので、以下にして画像のデータと文章のデータをモデルに学習させるかがポイントになってくるかと思います。\n",
        "\n",
        "画像のデータを特徴量として用いるために、今回はDenseNet121の学習済みモデルを用います。"
      ],
      "metadata": {
        "id": "0yLcrqu6GsfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from keras.models import Model\n",
        "from keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\n",
        "import keras.backend as K\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from keras.applications.densenet import preprocess_input, DenseNet121"
      ],
      "metadata": {
        "id": "Y2u7Txq3BgnO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    img_size = 224\n",
        "    batch_size = 17"
      ],
      "metadata": {
        "id": "ffiWtaKaHCe9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_to_square(im):\n",
        "    old_size = im.shape[:2] \n",
        "    ratio = float(CFG.img_size)/max(old_size)\n",
        "    new_size = tuple([int(x*ratio) for x in old_size])\n",
        "    # 画像サイズを224×224に変更します\n",
        "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
        "    delta_w = CFG.img_size - new_size[1]\n",
        "    delta_h = CFG.img_size - new_size[0]\n",
        "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
        "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
        "    color = [0, 0, 0]\n",
        "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
        "    return new_im\n",
        "\n",
        "\n",
        "def load_image(ids, is_train=True):\n",
        "  if is_train:\n",
        "    image = cv2.imread(train_image_path+ids)\n",
        "  else:\n",
        "    image = cv2.imread(test_image_path+ids)\n",
        "  new_image = resize_to_square(image)\n",
        "  new_image = preprocess_input(new_image)\n",
        "  return new_image"
      ],
      "metadata": {
        "id": "y2VMGIT1HFaE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = Input((224,224,3))\n",
        "backbone = DenseNet121(input_tensor = inp, include_top = False)\n",
        "x = backbone.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Lambda(lambda x: K.expand_dims(x,axis = -1))(x)\n",
        "x = AveragePooling1D(4)(x)\n",
        "out = Lambda(lambda x: x[:,:,0])(x)\n",
        "\n",
        "m = Model(inp,out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UR-JjVdMzh-y",
        "outputId": "139155a2-dde2-492a-a152-b99df14eeb6c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 0s 0us/step\n",
            "29097984/29084464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_df_train = train_df[[\"id\", \"odai_photo_file_name\"]].copy()\n",
        "image_df_train.head()"
      ],
      "metadata": {
        "id": "E__Maa9sHotq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "24b7e18b-641e-453e-d853-2d85716224d8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id odai_photo_file_name\n",
              "0  ge5kssftl       9fkys1gb2r.jpg\n",
              "1  r7sm6tvkj       c6ag0m1lak.jpg\n",
              "2  yp5aze0bh       whtn6gb9ww.jpg\n",
              "3  ujaixzo56       6yk5cwmrsy.jpg\n",
              "4  7vkeveptl       0i9gsa2jsm.jpg"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dceda592-18a1-447c-a620-8fdc3f2d0aa1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>odai_photo_file_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ge5kssftl</td>\n",
              "      <td>9fkys1gb2r.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>r7sm6tvkj</td>\n",
              "      <td>c6ag0m1lak.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yp5aze0bh</td>\n",
              "      <td>whtn6gb9ww.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ujaixzo56</td>\n",
              "      <td>6yk5cwmrsy.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7vkeveptl</td>\n",
              "      <td>0i9gsa2jsm.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dceda592-18a1-447c-a620-8fdc3f2d0aa1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dceda592-18a1-447c-a620-8fdc3f2d0aa1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dceda592-18a1-447c-a620-8fdc3f2d0aa1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_ids = image_df_train[\"odai_photo_file_name\"].values\n",
        "n_batches = len(image_ids) // CFG.batch_size + 1"
      ],
      "metadata": {
        "id": "88WZT_GRIZJd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = {}\n",
        "for b in tqdm(range(n_batches)):\n",
        "    start = b*CFG.batch_size\n",
        "    end = (b+1)*CFG.batch_size\n",
        "    batch_ids = image_ids[start:end]\n",
        "    batch_images = np.zeros((len(batch_ids),CFG.img_size,CFG.img_size,3))\n",
        "    for i,image_id in enumerate(batch_ids):\n",
        "        try:\n",
        "            batch_images[i] = load_image(image_id)\n",
        "        except:\n",
        "          print(\"Error\")\n",
        "    batch_preds = m.predict(batch_images)\n",
        "    for i,image_id in enumerate(batch_ids):\n",
        "        features[image_id] = batch_preds[i]"
      ],
      "metadata": {
        "id": "g6XwArKgIcCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75c371c4-8dfe-47df-b788-57ec87d2b708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 27/1469 [03:59<3:27:34,  8.64s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_feature = pd.DataFrame.from_dict(features, orient='index').add_prefix(\"DenseNet121_\").reset_index()\n",
        "image_feature.rename(columns={\"index\":\"odai_photo_file_name\"}, inplace=True)"
      ],
      "metadata": {
        "id": "T3x9JsVsI3ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainのデータに結合します。\n",
        "train_df = pd.merge(train_df, image_feature, on=\"odai_photo_file_name\", how=\"left\")"
      ],
      "metadata": {
        "id": "pNZpZ19iJEun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "id": "TLa8BVy5y4mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testデータでも同様なことを行って行きます\n",
        "image_df_test = test_df[[\"id\", \"odai_photo_file_name\"]].copy()\n",
        "\n",
        "image_ids = image_df_test[\"odai_photo_file_name\"].values\n",
        "n_batches = len(image_ids) // CFG.batch_size + 1\n",
        "\n",
        "\n",
        "features = {}\n",
        "for b in tqdm(range(n_batches)):\n",
        "    start = b*CFG.batch_size\n",
        "    end = (b+1)*CFG.batch_size\n",
        "    batch_ids = image_ids[start:end]\n",
        "    batch_images = np.zeros((len(batch_ids),CFG.img_size,CFG.img_size,3))\n",
        "    for i,image_id in enumerate(batch_ids):\n",
        "        try:\n",
        "            batch_images[i] = load_image(image_id, is_train=False)\n",
        "        except:\n",
        "          print(\"Error\")\n",
        "    batch_preds = m.predict(batch_images)\n",
        "    for i,image_id in enumerate(batch_ids):\n",
        "        features[image_id] = batch_preds[i]\n",
        "\n",
        "image_feature = pd.DataFrame.from_dict(features, orient='index').add_prefix(\"DenseNet121_\").reset_index()\n",
        "image_feature.rename(columns={\"index\":\"odai_photo_file_name\"}, inplace=True)\n",
        "\n",
        "test_df = pd.merge(test_df, image_feature, on=\"odai_photo_file_name\", how=\"left\")"
      ],
      "metadata": {
        "id": "ARlBMAiBxcVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.shape"
      ],
      "metadata": {
        "id": "_xtltEAbzoko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Text Features\n",
        "\n",
        "続いてボケての文章について、BERTモデルを用いて特徴量化していきます。\n",
        "特徴量化については、以下のディスカッションを参考にさせていただきます。  \n",
        "[japanese-roberta-baseでテキストデータをembeddingする(小説家になろう ブクマ数予測 \\~”伸びる”タイトルとは？\\~ より)](https://www.nishika.com/competitions/21/topics/163)\n"
      ],
      "metadata": {
        "id": "cJAXTezHLBm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    replaced_text = text.lower()\n",
        "    replaced_text = re.sub(r'[【】]', ' ', replaced_text)       # 【】の除去\n",
        "    replaced_text = re.sub(r'[（）()]', ' ', replaced_text)     # （）の除去\n",
        "    replaced_text = re.sub(r'[［］\\[\\]]', ' ', replaced_text)   # ［］の除去\n",
        "    replaced_text = re.sub(r'[『』]', ' ', replaced_text)   # 『』の除去\n",
        "    replaced_text = re.sub(r'[@＠]\\w+', '', replaced_text)  # メンションの除去\n",
        "    replaced_text = re.sub(r'https?:\\/\\/.*?[\\r\\n ]', '', replaced_text)  # URLの除去\n",
        "    replaced_text = re.sub(r'　', ' ', replaced_text)  # 全角空白の除去\n",
        "    replaced_text = re.sub(r' ', '', replaced_text)  # 空白の除去\n",
        "    return replaced_text\n",
        "\n",
        "\n",
        "def clean_html_tags(html_text):\n",
        "    soup = BeautifulSoup(html_text, 'html.parser')\n",
        "    cleaned_text = soup.get_text()\n",
        "    cleaned_text = ''.join(cleaned_text.splitlines())\n",
        "    return cleaned_text\n",
        "\n",
        "\n",
        "def clean_html_and_js_tags(html_text):\n",
        "    soup = BeautifulSoup(html_text, 'html.parser')\n",
        "    [x.extract() for x in soup.findAll(['script', 'style'])]\n",
        "    cleaned_text = soup.get_text()\n",
        "    cleaned_text = ''.join(cleaned_text.splitlines())\n",
        "    return cleaned_text\n",
        "\n",
        "\n",
        "def clean_url(html_text):\n",
        "    cleaned_text = re.sub(r'http\\S+', '', html_text)\n",
        "    return cleaned_text\n",
        "\n",
        "\n",
        "def normalize(text):\n",
        "    normalized_text = normalize_unicode(text)\n",
        "    normalized_text = normalize_number(normalized_text)\n",
        "    normalized_text = lower_text(normalized_text)\n",
        "    return normalized_text\n",
        "\n",
        "\n",
        "def lower_text(text):\n",
        "    return text.lower()\n",
        "\n",
        "\n",
        "def normalize_unicode(text, form='NFKC'):\n",
        "    normalized_text = unicodedata.normalize(form, text)\n",
        "    return normalized_text\n",
        "\n",
        "\n",
        "def normalize_number(text):\n",
        "    replaced_text = re.sub(r'\\d+', '0', text)\n",
        "    return replaced_text\n",
        "\n",
        "\n",
        "def text_cleaning(text):\n",
        "    text = clean_text(text)\n",
        "    text = clean_html_tags(text)\n",
        "    text = clean_html_and_js_tags(text)\n",
        "    text = clean_url(text)\n",
        "    text = normalize(text)\n",
        "    text = lower_text(text)\n",
        "    text = normalize_unicode(text)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "vJUPWqtXK_k_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertSequenceVectorizer:\n",
        "    def __init__(self, model_name: str):\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.model_name = model_name\n",
        "        self.tokenizer = transformers.T5Tokenizer.from_pretrained(self.model_name)\n",
        "        self.tokenizer.do_lower_case = True \n",
        "        self.bert_model = transformers.RobertaModel.from_pretrained(self.model_name)\n",
        "        self.bert_model = self.bert_model.to(self.device)\n",
        "        self.max_len = 256\n",
        "\n",
        "\n",
        "    def vectorize(self, sentence : str) -> np.array:\n",
        "        inp = self.tokenizer.encode(sentence)\n",
        "        len_inp = len(inp)\n",
        "\n",
        "        if len_inp >= self.max_len:\n",
        "            inputs = inp[:self.max_len]\n",
        "            masks = [1] * self.max_len\n",
        "        else:\n",
        "            inputs = inp + [0] * (self.max_len - len_inp)\n",
        "            masks = [1] * len_inp + [0] * (self.max_len - len_inp)\n",
        "\n",
        "        inputs_tensor = torch.tensor([inputs], dtype=torch.long).to(self.device)\n",
        "        masks_tensor = torch.tensor([masks], dtype=torch.long).to(self.device)\n",
        "\n",
        "        bert_out = self.bert_model(inputs_tensor, masks_tensor)\n",
        "        seq_out, pooled_out = bert_out['last_hidden_state'], bert_out['pooler_output']\n",
        "\n",
        "        if torch.cuda.is_available():    \n",
        "            return seq_out[0][0].cpu().detach().numpy()\n",
        "        else:\n",
        "            return seq_out[0][0].detach().numpy()"
      ],
      "metadata": {
        "id": "bK4VlYAFLZI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BSV = BertSequenceVectorizer('rinna/japanese-roberta-base')\n",
        "\n",
        "## テキストの欠損値を補間します\n",
        "train_df[\"text\"] = train_df[\"text\"].fillna('NaN')\n",
        "test_df[\"text\"] = test_df[\"text\"].fillna('NaN')\n",
        "\n",
        "## BERT特徴量 \n",
        "features_text_train = np.stack(train_df[\"text\"].fillna(\"\").map(lambda x: BSV.vectorize(x).reshape(-1)).values)\n",
        "features_text_test = np.stack(test_df[\"text\"].fillna(\"\").map(lambda x: BSV.vectorize(x).reshape(-1)).values)"
      ],
      "metadata": {
        "id": "GIor4FKq1hbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## テキスト特徴量\n",
        "features_text_train_df = pd.DataFrame(features_text_train).add_prefix(\"Roberta-text\")\n",
        "features_text_test_df = pd.DataFrame(features_text_test).add_prefix(\"Roberta-text\")\n",
        "\n",
        "train_df = pd.concat([train_df, features_text_train_df], axis=1)\n",
        "test_df = pd.concat([test_df, features_text_test_df], axis=1)"
      ],
      "metadata": {
        "id": "U1I7xF2Y19MX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.shape)\n",
        "print(test_df.shape)"
      ],
      "metadata": {
        "id": "i-dWAwir54xN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv('/content/drive/MyDrive/nishika/embeded/embedding_train_densenet151_rinna_roberta_base.csv')"
      ],
      "metadata": {
        "id": "Hj68OivBX6sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('/content/drive/MyDrive/nishika/embeded/embedding_test_densenet151_rinna_roberta_base.csv')"
      ],
      "metadata": {
        "id": "LsxA0p2yYKPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"is_laugh\"].value_counts()"
      ],
      "metadata": {
        "id": "fL4aJeMLYUWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Split"
      ],
      "metadata": {
        "id": "H4K63PLc6oGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習データと評価データに分割します\n",
        "train_df, valid_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df[\"is_laugh\"])\n",
        "\n",
        "train_y = train_df[\"is_laugh\"]\n",
        "train_x = train_df.drop([\"id\", \"odai_photo_file_name\", \"text\",\"is_laugh\"], axis=1)\n",
        "\n",
        "valid_y = valid_df[\"is_laugh\"]\n",
        "valid_x = valid_df.drop([\"id\", \"odai_photo_file_name\", \"text\",\"is_laugh\"], axis=1)\n",
        "\n",
        "test_x = test_df.drop([\"id\", \"odai_photo_file_name\", \"text\"], axis=1)"
      ],
      "metadata": {
        "id": "0pInRB316fFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_x.shape)\n",
        "print(valid_x.shape)"
      ],
      "metadata": {
        "id": "2DyOqFn57PAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "jtw_IUp87-HP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_params = {  \n",
        "    \"n_estimators\": 20000,\n",
        "    \"objective\": 'binary',\n",
        "    \"learning_rate\": 0.05,\n",
        "    \"num_leaves\": 32,\n",
        "    \"random_state\": 71,\n",
        "    \"n_jobs\": -1,\n",
        "    \"importance_type\": \"gain\",\n",
        "    'colsample_bytree': .8,\n",
        "    \"reg_lambda\": 5,\n",
        "    \"max_depth\":5,\n",
        "    }\n",
        "\n",
        "lgtrain = lgb.Dataset(train_x, train_y)\n",
        "lgvalid = lgb.Dataset(valid_x, valid_y)\n",
        "\n",
        "lgb_clf = lgb.train(\n",
        "    lgbm_params,\n",
        "    lgtrain,\n",
        "    num_boost_round=10000,\n",
        "    valid_sets=[lgtrain, lgvalid],\n",
        "    valid_names=['train','valid'],\n",
        "    early_stopping_rounds=50,\n",
        "    verbose_eval=50\n",
        ")"
      ],
      "metadata": {
        "id": "dZS_euCU79xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徴量の重要度を可視化。\n",
        "lgb.plot_importance(lgb_clf, figsize=(12,8), max_num_features=50, importance_type='gain')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5m1V_v6T9vMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 評価指標はlog lossだが、accuracyも見てみる\n",
        "\n",
        "val_pred = lgb_clf.predict(valid_x, num_iteration=lgb_clf.best_iteration)\n",
        "val_pred_max = np.round(lgb_clf.predict(valid_x)).astype(int)  # クラスに分類\n",
        "accuracy = sum(valid_y == val_pred_max) / len(valid_y)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "qQaVWqkTAZ74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_conf_options = {\"normalize\": None,}\n",
        "_plot_options = {\n",
        "        \"cmap\": \"Blues\",\n",
        "        \"annot\": True\n",
        "    }\n",
        "\n",
        "conf = confusion_matrix(y_true=valid_y,\n",
        "                        y_pred=val_pred_max,\n",
        "                        **_conf_options)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "sns.heatmap(conf, ax=ax, **_plot_options)\n",
        "ax.set_ylabel(\"Label\")\n",
        "ax.set_xlabel(\"Predict\")"
      ],
      "metadata": {
        "id": "FPX2pXaZBMpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "id": "sBad8xkWAXi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = lgb_clf.predict(test_x, num_iteration=lgb_clf.best_iteration)"
      ],
      "metadata": {
        "id": "gGvSdvMH-hq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df[\"is_laugh\"] = test_pred\n",
        "submission_df.head()"
      ],
      "metadata": {
        "id": "p8g6BTPjCg9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df.to_csv(('/content/drive/MyDrive/nishika/sub.csv'), index=False)"
      ],
      "metadata": {
        "id": "mEhTo6Leu02p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "実際に提出して、スコアを確認してみましょう。  精度向上に向けて様々なアイディアがあるかと思いますので、ぜひいろいろとトライしていただければと思います！\n",
        "\n",
        "- 異なる学習済みモデルでの特徴量化\n",
        "- 画像の状況とボケての文章との解離具合を測定する\n",
        "- 説明文口調とセリフ口調の分類をしてみる。\n",
        "- 画像に何が写っているかを検出し、特徴量に加えてみる（人が写っている。動物が写っている）\n"
      ],
      "metadata": {
        "id": "VSDaDtajVF3F"
      }
    }
  ]
}