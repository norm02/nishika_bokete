{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0ayzrjm-DgE"
      },
      "source": [
        "# ボケ判定AIを作ろう！-チュートリアル1\n",
        "このnotebookは、Nishikaコンペティション [ボケ判定AIを作ろう！](https://www.nishika.com/competitions/) のチュートリアルです。\n",
        "\n",
        "「ボケて」データを用いて、画像データと文章からそのボケてが面白いか面白くないかを予測することをテーマとしています。\n",
        "\n",
        "このNotebookでは、画像とテキストそれぞれの特徴量生成を以下のような方法で行っていきます。\n",
        "\n",
        "- CNNモデルを用いた画像データの特徴量化\n",
        "- BERTモデルを用いたテキストデータの特徴量化\n",
        "\n",
        "特徴量の作成では、テキストと画像それぞれ別々で作成していますので、画像データとテキストデータを組み合わせた特徴量を入れることで精度向上が見込めるかも知れませんので、いろいろと試していただければと思います。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjvjywgsCuKU"
      },
      "source": [
        "| 要素 | 説明 |\n",
        "| ---- | ---- |\n",
        "|id | ID|\n",
        "|odai_photo_file_name | ボケてのお題画像|\n",
        "|text | ボケての文章|\n",
        "|is_laugh | 面白さ（面白い：１、面白くない：０）|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YJVABJ8CqoX"
      },
      "source": [
        "ディレクトリ構成は以下のように設定します\n",
        "\n",
        "```\n",
        "├── train.zip\n",
        "│ ├── xxx.jpg\n",
        "│ └── yyy.jpg\n",
        "├── test.zip\n",
        "│ ├── xxx.jpg\n",
        "│ └── yyy.jpg\n",
        "├── train.csv\n",
        "├── test.csv\n",
        "├── sample_submission.csv\n",
        "└── submission.csv(今回のbaselineで生成されるsubmissionファイル)\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "### setting\n",
        "ページ上部の「ランタイム」>「ランタイムのタイプを変更」から「GPU」「ハイメモリ」を選択"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exPnU6gJ9_8L",
        "outputId": "76f9f112-10f0-418e-b9c9-590edb1e2909"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9onj0RDDiWU4",
        "outputId": "a7c2a674-535c-43b2-bb8c-1f106dbfc310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep  5 08:41:06 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGai1EPR_tEA"
      },
      "source": [
        "# Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23tLb36S_nX-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f3b7945-86e4-4a61-f356-af24e4769177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.0 MB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 65.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 880 kB 82.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 73.3 MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 4.3 MB/s \n",
            "\u001b[?25h  Building wheel for japanize-matplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet transformers==4.18.0\n",
        "!pip install --quiet tokenizers==0.12.1\n",
        "!pip install --quiet sentencepiece\n",
        "!pip install --quiet japanize-matplotlib\n",
        "!pip install transformers fugashi ipadic >> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTpVfTxzI2tx"
      },
      "outputs": [],
      "source": [
        "!pip install keras-efficientnet-v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myu_A_Kc_zyK",
        "outputId": "517cdcc2-5b8a-4c6b-a479-12aa62875903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import japanize_matplotlib\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertJapaneseTokenizer, AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "\n",
        "from time import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "from contextlib import contextmanager\n",
        "import lightgbm as lgb\n",
        "\n",
        "import re\n",
        "import requests\n",
        "import unicodedata\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from bs4 import BeautifulSoup\n",
        "nltk.download(['wordnet', 'stopwords', 'punkt'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCYVrA1lAB8L"
      },
      "source": [
        "# Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKk0ahsSIzJY"
      },
      "outputs": [],
      "source": [
        "pd.set_option('max_rows', 400)\n",
        "pd.set_option('max_columns', 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9WsZjx-NT-O"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed=1234):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "seed_everything(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajiBxfC2ABC4"
      },
      "outputs": [],
      "source": [
        "INPUT = \"/content/drive/MyDrive/nishika/\" # 所望のディレクトリに変更してください。\n",
        "train_image_path = \"/content/drive/MyDrive/nishika/train/\"\n",
        "test_image_path = \"/content/drive/MyDrive/nishika/test/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbdARhsQASHE"
      },
      "source": [
        "# Read Data\n",
        "学習データと推論データについて、目的変数の分布などを確認していきます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh06H3rFAPA5"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(os.path.join(INPUT, \"train.csv\"))\n",
        "test_df = pd.read_csv(os.path.join(INPUT, \"test.csv\"))\n",
        "submission_df = pd.read_csv(os.path.join(INPUT, \"sample_submission.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "sofMAgYkAqmU",
        "outputId": "03b48ae5-76a6-4b12-ea72-d1ae8ed3e9c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data: (24962, 4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          id odai_photo_file_name  \\\n",
              "0  ge5kssftl       9fkys1gb2r.jpg   \n",
              "1  r7sm6tvkj       c6ag0m1lak.jpg   \n",
              "2  yp5aze0bh       whtn6gb9ww.jpg   \n",
              "3  ujaixzo56       6yk5cwmrsy.jpg   \n",
              "4  7vkeveptl       0i9gsa2jsm.jpg   \n",
              "\n",
              "                                            text  is_laugh  \n",
              "0             君しょっちゅうソレ自慢するけど、ツムジ２個ってそんなに嬉しいのかい？         0  \n",
              "1                            これでバレない？授業中寝てもバレない？         0  \n",
              "2  「あなたも感じる？」\\n『ああ…、感じてる…』\\n「後ろに幽霊いるよね…」\\n『女のな…』         0  \n",
              "3                 大塚愛聞いてたらお腹減った…さく、らんぼと牛タン食べたい…          0  \n",
              "4                                    熊だと思ったら嫁だった         0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3474449-c242-426e-ba70-560e8ec48317\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>odai_photo_file_name</th>\n",
              "      <th>text</th>\n",
              "      <th>is_laugh</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ge5kssftl</td>\n",
              "      <td>9fkys1gb2r.jpg</td>\n",
              "      <td>君しょっちゅうソレ自慢するけど、ツムジ２個ってそんなに嬉しいのかい？</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>r7sm6tvkj</td>\n",
              "      <td>c6ag0m1lak.jpg</td>\n",
              "      <td>これでバレない？授業中寝てもバレない？</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yp5aze0bh</td>\n",
              "      <td>whtn6gb9ww.jpg</td>\n",
              "      <td>「あなたも感じる？」\\n『ああ…、感じてる…』\\n「後ろに幽霊いるよね…」\\n『女のな…』</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ujaixzo56</td>\n",
              "      <td>6yk5cwmrsy.jpg</td>\n",
              "      <td>大塚愛聞いてたらお腹減った…さく、らんぼと牛タン食べたい…</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7vkeveptl</td>\n",
              "      <td>0i9gsa2jsm.jpg</td>\n",
              "      <td>熊だと思ったら嫁だった</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3474449-c242-426e-ba70-560e8ec48317')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3474449-c242-426e-ba70-560e8ec48317 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3474449-c242-426e-ba70-560e8ec48317');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_data: (6000, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          id odai_photo_file_name  \\\n",
              "0  rfdjcfsqq       nc1kez326b.jpg   \n",
              "1  tsgqmfpef       49xt2fmjw0.jpg   \n",
              "2  owjcthkz2       9dtscjmyfh.jpg   \n",
              "3  rvgaocjyy       osa3n56tiv.jpg   \n",
              "4  uxtwu5i69       yb1yqs4pvb.jpg   \n",
              "\n",
              "                                                text  \n",
              "0                          僕のママ、キャラ弁のゆでたまごに８時間かかったんだ  \n",
              "1                                          かわいいが作れた！  \n",
              "2                                           来世の志茂田景樹  \n",
              "3                       ちょ、あの、オカン、これ水風呂やねんけど、なんの冗談??  \n",
              "4  「今日は皆さんにザリガニと消防車の違いを知ってもらいたいと思います」『どっちも同じだろ。両方...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d8820ee-fb69-4138-b6da-88e76a7c8ae5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>odai_photo_file_name</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rfdjcfsqq</td>\n",
              "      <td>nc1kez326b.jpg</td>\n",
              "      <td>僕のママ、キャラ弁のゆでたまごに８時間かかったんだ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tsgqmfpef</td>\n",
              "      <td>49xt2fmjw0.jpg</td>\n",
              "      <td>かわいいが作れた！</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>owjcthkz2</td>\n",
              "      <td>9dtscjmyfh.jpg</td>\n",
              "      <td>来世の志茂田景樹</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rvgaocjyy</td>\n",
              "      <td>osa3n56tiv.jpg</td>\n",
              "      <td>ちょ、あの、オカン、これ水風呂やねんけど、なんの冗談??</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>uxtwu5i69</td>\n",
              "      <td>yb1yqs4pvb.jpg</td>\n",
              "      <td>「今日は皆さんにザリガニと消防車の違いを知ってもらいたいと思います」『どっちも同じだろ。両方...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d8820ee-fb69-4138-b6da-88e76a7c8ae5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3d8820ee-fb69-4138-b6da-88e76a7c8ae5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3d8820ee-fb69-4138-b6da-88e76a7c8ae5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(f\"train_data: {train_df.shape}\")\n",
        "display(train_df.head())\n",
        "\n",
        "print(f\"test_data: {test_df.shape}\")\n",
        "display(test_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "ESnHK1cV0lBK",
        "outputId": "7f5b2ba9-5be9-4314-bf7b-1418d97e2ff2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f29e52f8cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# 目的変数の分布を確認する\n",
        "sns.countplot(x=\"is_laugh\", data=train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxXxnkwVX2Gm",
        "outputId": "225fd45a-d486-47f6-df79-1e8dd77b4f72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    12481\n",
              "1    12481\n",
              "Name: is_laugh, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_df[\"is_laugh\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PefMwabDA_T2",
        "outputId": "7fffe128-648a-4b7b-8d5d-4ec1e89a3095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# 画像の重複があるか確認する\n",
        "print(train_df[\"odai_photo_file_name\"].duplicated().sum())\n",
        "print(test_df[\"odai_photo_file_name\"].duplicated().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "1O2ve9Te6oFN",
        "outputId": "ea685165-9819-431a-c974-8b0fa02a7c36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f29e2cedc10>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# 文書の長さとflagの関係を確認する\n",
        "train_df[\"text_len\"] = train_df[\"text\"].str.len()\n",
        "test_df[\"text_len\"] = test_df[\"text\"].str.len()\n",
        "\n",
        "sns.boxplot(x=\"is_laugh\", y=\"text_len\", data=train_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6csg_bf-1kS6"
      },
      "source": [
        "目的変数の分布と、文章の長さについて確認しました。続いて、実際に画像と文章を合わせてみてみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_fWdrXRxBqf"
      },
      "source": [
        "個人的な主観も含まれてしまいますが、以下のようなことがわかってきました。  \n",
        "- ファイル名で確認すると、画像の重複はtrainとtestではない。\n",
        "- ボケての文章の長さを確認すると、面白いボケての方が文章が長い傾向\n",
        "- 画像とボケての文章を見てみると、確かに１と０で差がありそう（個人的に０の方はどのようにボケているのかが少しわかりにくい感じがあります）\n",
        "\n",
        "今回は単純に文章の長さのみを確認しましたが、他にも文章自体について注目していくと、面白さに関する知見というのが見えてくるかも知れません。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yLcrqu6GsfK"
      },
      "source": [
        "# Create Image Features\n",
        "\n",
        "ボケてというものは、画像と文章の組み合わせで面白さを表現しているので、以下にして画像のデータと文章のデータをモデルに学習させるかがポイントになってくるかと思います。\n",
        "\n",
        "画像のデータを特徴量として用いるために、今回はDenseNet121の学習済みモデルを用います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2u7Txq3BgnO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "cd7d0ed9-4a80-41f0-bf87-c664f9376039"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport cv2\\nfrom keras.models import Model\\nfrom keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\\nimport keras.backend as K\\nfrom tqdm import tqdm, tqdm_notebook\\nfrom keras.applications.efficientnet_v2 import preprocess_input, EfficientNetV2L\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "\n",
        "import cv2\n",
        "from keras.models import Model\n",
        "from keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\n",
        "import keras.backend as K\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from keras.applications.efficientnet_v2 import preprocess_input, EfficientNetV2L\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffiWtaKaHCe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7003603e-53d7-4637-f53e-fcea05177e84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass CFG:\\n    img_size = 480\\n    batch_size = 17\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "\n",
        "class CFG:\n",
        "    img_size = 480\n",
        "    batch_size = 17\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2VMGIT1HFaE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "b8ae27cf-5902-4103-ea4e-fa303b8c1bdf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef resize_to_square(im):\\n    old_size = im.shape[:2] \\n    ratio = float(CFG.img_size)/max(old_size)\\n    new_size = tuple([int(x*ratio) for x in old_size])\\n    # 画像サイズを224×224に変更します\\n    im = cv2.resize(im, (new_size[1], new_size[0]))\\n    delta_w = CFG.img_size - new_size[1]\\n    delta_h = CFG.img_size - new_size[0]\\n    top, bottom = delta_h//2, delta_h-(delta_h//2)\\n    left, right = delta_w//2, delta_w-(delta_w//2)\\n    color = [0, 0, 0]\\n    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\\n    return new_im\\n\\n\\ndef load_image(ids, is_train=True):\\n  if is_train:\\n    image = cv2.imread(train_image_path+ids)\\n  else:\\n    image = cv2.imread(test_image_path+ids)\\n  new_image = resize_to_square(image)\\n  new_image = preprocess_input(new_image)\\n  return new_image\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "\n",
        "def resize_to_square(im):\n",
        "    old_size = im.shape[:2] \n",
        "    ratio = float(CFG.img_size)/max(old_size)\n",
        "    new_size = tuple([int(x*ratio) for x in old_size])\n",
        "    # 画像サイズを224×224に変更します\n",
        "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
        "    delta_w = CFG.img_size - new_size[1]\n",
        "    delta_h = CFG.img_size - new_size[0]\n",
        "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
        "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
        "    color = [0, 0, 0]\n",
        "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
        "    return new_im\n",
        "\n",
        "\n",
        "def load_image(ids, is_train=True):\n",
        "  if is_train:\n",
        "    image = cv2.imread(train_image_path+ids)\n",
        "  else:\n",
        "    image = cv2.imread(test_image_path+ids)\n",
        "  new_image = resize_to_square(image)\n",
        "  new_image = preprocess_input(new_image)\n",
        "  return new_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fuel9pkhenp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b256bf46-2db8-4424-b93e-f043b7403398"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ninp = Input((480,480,3))\\nbackbone = EfficientNetV2L(input_tensor = inp, include_top = False)\\nx = backbone.output\\nx = GlobalAveragePooling2D()(x)\\nx = Lambda(lambda x: K.expand_dims(x,axis = -1))(x)\\nx = AveragePooling1D(4)(x)\\nout = Lambda(lambda x: x[:,:,0])(x)\\n\\nm = Model(inp,out)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "\n",
        "inp = Input((480,480,3))\n",
        "backbone = EfficientNetV2L(input_tensor = inp, include_top = False)\n",
        "x = backbone.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Lambda(lambda x: K.expand_dims(x,axis = -1))(x)\n",
        "x = AveragePooling1D(4)(x)\n",
        "out = Lambda(lambda x: x[:,:,0])(x)\n",
        "\n",
        "m = Model(inp,out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E__Maa9sHotq"
      },
      "outputs": [],
      "source": [
        "image_df_train = train_df[[\"id\", \"odai_photo_file_name\"]].copy()\n",
        "image_df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88WZT_GRIZJd"
      },
      "outputs": [],
      "source": [
        "image_ids = image_df_train[\"odai_photo_file_name\"].values\n",
        "n_batches = len(image_ids) // CFG.batch_size + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "g6XwArKgIcCr",
        "outputId": "db6f9c19-b81e-41c7-a8de-5a8ba59ec793"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfeatures = {}\\nfor b in tqdm(range(n_batches)):\\n    start = b*CFG.batch_size\\n    end = (b+1)*CFG.batch_size\\n    batch_ids = image_ids[start:end]\\n    batch_images = np.zeros((len(batch_ids),CFG.img_size,CFG.img_size,3))\\n    for i,image_id in enumerate(batch_ids):\\n        try:\\n            batch_images[i] = load_image(image_id)\\n        except:\\n          print(\"Error\")\\n    batch_preds = m.predict(batch_images)\\n    for i,image_id in enumerate(batch_ids):\\n        features[image_id] = batch_preds[i]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "\n",
        "features = {}\n",
        "for b in tqdm(range(n_batches)):\n",
        "    start = b*CFG.batch_size\n",
        "    end = (b+1)*CFG.batch_size\n",
        "    batch_ids = image_ids[start:end]\n",
        "    batch_images = np.zeros((len(batch_ids),CFG.img_size,CFG.img_size,3))\n",
        "    for i,image_id in enumerate(batch_ids):\n",
        "        try:\n",
        "            batch_images[i] = load_image(image_id)\n",
        "        except:\n",
        "          print(\"Error\")\n",
        "    batch_preds = m.predict(batch_images)\n",
        "    for i,image_id in enumerate(batch_ids):\n",
        "        features[image_id] = batch_preds[i]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3x9JsVsI3ht"
      },
      "outputs": [],
      "source": [
        "image_feature = pd.DataFrame.from_dict(features, orient='index').add_prefix(\"EfficientNetV2L_\").reset_index()\n",
        "image_feature.rename(columns={\"index\":\"odai_photo_file_name\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNZpZ19iJEun"
      },
      "outputs": [],
      "source": [
        "# trainのデータに結合します。\n",
        "train_df = pd.merge(train_df, image_feature, on=\"odai_photo_file_name\", how=\"left\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLa8BVy5y4mh"
      },
      "outputs": [],
      "source": [
        "train_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "ARlBMAiBxcVP",
        "outputId": "1141bedb-fc80-411b-e4c7-0a9a17bbf783"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# testデータでも同様なことを行って行きます\\nimage_df_test = test_df[[\"id\", \"odai_photo_file_name\"]].copy()\\n\\nimage_ids = image_df_test[\"odai_photo_file_name\"].values\\nn_batches = len(image_ids) // CFG.batch_size + 1\\n\\n\\nfeatures = {}\\nfor b in tqdm(range(n_batches)):\\n    start = b*CFG.batch_size\\n    end = (b+1)*CFG.batch_size\\n    batch_ids = image_ids[start:end]\\n    batch_images = np.zeros((len(batch_ids),CFG.img_size,CFG.img_size,3))\\n    for i,image_id in enumerate(batch_ids):\\n        try:\\n            batch_images[i] = load_image(image_id, is_train=False)\\n        except:\\n          print(\"Error\")\\n    batch_preds = m.predict(batch_images)\\n    for i,image_id in enumerate(batch_ids):\\n        features[image_id] = batch_preds[i]\\n\\nimage_feature = pd.DataFrame.from_dict(features, orient=\\'index\\').add_prefix(\"EfficientNetV2L_\").reset_index()\\nimage_feature.rename(columns={\"index\":\"odai_photo_file_name\"}, inplace=True)\\n\\ntest_df = pd.merge(test_df, image_feature, on=\"odai_photo_file_name\", how=\"left\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "\n",
        "# testデータでも同様なことを行って行きます\n",
        "image_df_test = test_df[[\"id\", \"odai_photo_file_name\"]].copy()\n",
        "\n",
        "image_ids = image_df_test[\"odai_photo_file_name\"].values\n",
        "n_batches = len(image_ids) // CFG.batch_size + 1\n",
        "\n",
        "\n",
        "features = {}\n",
        "for b in tqdm(range(n_batches)):\n",
        "    start = b*CFG.batch_size\n",
        "    end = (b+1)*CFG.batch_size\n",
        "    batch_ids = image_ids[start:end]\n",
        "    batch_images = np.zeros((len(batch_ids),CFG.img_size,CFG.img_size,3))\n",
        "    for i,image_id in enumerate(batch_ids):\n",
        "        try:\n",
        "            batch_images[i] = load_image(image_id, is_train=False)\n",
        "        except:\n",
        "          print(\"Error\")\n",
        "    batch_preds = m.predict(batch_images)\n",
        "    for i,image_id in enumerate(batch_ids):\n",
        "        features[image_id] = batch_preds[i]\n",
        "\n",
        "image_feature = pd.DataFrame.from_dict(features, orient='index').add_prefix(\"EfficientNetV2L_\").reset_index()\n",
        "image_feature.rename(columns={\"index\":\"odai_photo_file_name\"}, inplace=True)\n",
        "\n",
        "test_df = pd.merge(test_df, image_feature, on=\"odai_photo_file_name\", how=\"left\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xtltEAbzoko",
        "outputId": "e169173d-7ee8-4c82-9af5-85226dfbc547"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6000, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "test_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4K63PLc6oGW"
      },
      "source": [
        "# Data Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZtMzyJl_XAY"
      },
      "outputs": [],
      "source": [
        "print(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習データと評価データに分割します\n",
        "train_df, valid_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df[\"is_laugh\"])\n",
        "\n",
        "train_y = train_df[\"is_laugh\"]\n",
        "train_x = train_df.drop([\"id\", \"odai_photo_file_name\", \"text\",\"is_laugh\"], axis=1)\n",
        "\n",
        "valid_y = valid_df[\"is_laugh\"]\n",
        "valid_x = valid_df.drop([\"id\", \"odai_photo_file_name\", \"text\",\"is_laugh\"], axis=1)\n",
        "\n",
        "test_x = test_df.drop([\"id\", \"odai_photo_file_name\", \"text\"], axis=1)"
      ],
      "metadata": {
        "id": "gMagxnDLG7Xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DyOqFn57PAA"
      },
      "outputs": [],
      "source": [
        "print(train_x.shape)\n",
        "print(valid_x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtw_IUp87-HP"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZS_euCU79xd"
      },
      "outputs": [],
      "source": [
        "lgbm_params = {  \n",
        "    \"n_estimators\": 20000,\n",
        "    \"objective\": 'binary',\n",
        "    \"learning_rate\": 0.05,\n",
        "    \"num_leaves\": 32,\n",
        "    \"random_state\": 71,\n",
        "    \"n_jobs\": -1,\n",
        "    \"importance_type\": \"gain\",\n",
        "    'colsample_bytree': .8,\n",
        "    \"reg_lambda\": 5,\n",
        "    \"max_depth\":5,\n",
        "    }\n",
        "\n",
        "lgtrain = lgb.Dataset(train_x, train_y)\n",
        "lgvalid = lgb.Dataset(valid_x, valid_y)\n",
        "\n",
        "lgb_clf = lgb.train(\n",
        "    lgbm_params,\n",
        "    lgtrain,\n",
        "    num_boost_round=10000,\n",
        "    valid_sets=[lgtrain, lgvalid],\n",
        "    valid_names=['train','valid'],\n",
        "    early_stopping_rounds=50,\n",
        "    verbose_eval=50\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5m1V_v6T9vMz"
      },
      "outputs": [],
      "source": [
        "# 特徴量の重要度を可視化。\n",
        "lgb.plot_importance(lgb_clf, figsize=(12,8), max_num_features=50, importance_type='gain')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQaVWqkTAZ74"
      },
      "outputs": [],
      "source": [
        "# 評価指標はlog lossだが、accuracyも見てみる\n",
        "\n",
        "val_pred = lgb_clf.predict(valid_x, num_iteration=lgb_clf.best_iteration)\n",
        "val_pred_max = np.round(lgb_clf.predict(valid_x)).astype(int)  # クラスに分類\n",
        "accuracy = sum(valid_y == val_pred_max) / len(valid_y)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPX2pXaZBMpu"
      },
      "outputs": [],
      "source": [
        "_conf_options = {\"normalize\": None,}\n",
        "_plot_options = {\n",
        "        \"cmap\": \"Blues\",\n",
        "        \"annot\": True\n",
        "    }\n",
        "\n",
        "conf = confusion_matrix(y_true=valid_y,\n",
        "                        y_pred=val_pred_max,\n",
        "                        **_conf_options)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "sns.heatmap(conf, ax=ax, **_plot_options)\n",
        "ax.set_ylabel(\"Label\")\n",
        "ax.set_xlabel(\"Predict\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBad8xkWAXi1"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGvSdvMH-hq5"
      },
      "outputs": [],
      "source": [
        "test_pred = lgb_clf.predict(test_x, num_iteration=lgb_clf.best_iteration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8g6BTPjCg9R"
      },
      "outputs": [],
      "source": [
        "submission_df[\"is_laugh\"] = test_pred\n",
        "submission_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wV2NPdgBEYM2"
      },
      "outputs": [],
      "source": [
        "submission_df.to_csv(('sub.csv'), index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSDaDtajVF3F"
      },
      "source": [
        "実際に提出して、スコアを確認してみましょう。  精度向上に向けて様々なアイディアがあるかと思いますので、ぜひいろいろとトライしていただければと思います！\n",
        "\n",
        "- 異なる学習済みモデルでの特徴量化\n",
        "- 画像の状況とボケての文章との解離具合を測定する\n",
        "- 説明文口調とセリフ口調の分類をしてみる。\n",
        "- 画像に何が写っているかを検出し、特徴量に加えてみる（人が写っている。動物が写っている）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m7QT4Ttk9Rv"
      },
      "source": [
        "https://lab.mo-t.com/blog/kaggle-shopee\n",
        "前処理については今回は気にしない。最終的なLightgbmにぶっこむ特徴量を増やして選別する方針でいく。\n",
        "エンベッディングした結果は保存する。\n",
        "最初は画像は画像、テキストはテキストでエンベッディングする。\n",
        "画像のArcFaceちょっとめんどい、実装できそうならやる\n",
        "knn(k=50)を使って、画像、テキストの分類自体はする。\n",
        "\n",
        "基本はエンベッディングしたものを使う。\n",
        "プラスで、特徴量を足してみる。\n",
        "乖離具合ってどうやって測定するのか\n",
        "・長文？なんかキーになる話がある？画像と関係？わからん\n",
        "・ボケのデザインパターン/ジョナサン・ハイト\n",
        "・既知未知判定ってどうやってやるんだ・・・\n",
        "・ポジネガ距離はおもろい。\n",
        "あえて正しいこととは逆なことをして、許されるライン的な話。\n",
        "→単純にえぐい言葉やえぐさを分類？なんかいいのないかな。\n",
        "説明文とセリフ文→なんかいい楽な分類ないかな、なかったら頑張る。\n",
        "画像に何が写っているか→うーん、手動しかないかも。"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}